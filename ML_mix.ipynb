{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21bf58f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T15:22:08.299068Z",
     "iopub.status.busy": "2023-09-04T15:22:08.298720Z",
     "iopub.status.idle": "2023-09-04T15:22:10.321713Z",
     "shell.execute_reply": "2023-09-04T15:22:10.320725Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "name = \"wild\"\n",
    "with open(\"features/features_\" + name + \".csv\", \"r\") as f:\n",
    "  line = f.readline()\n",
    "  feature_names = line.split(\",\")\n",
    "  feature_names.remove(\"name\")\n",
    "  feature_names.remove(\"write_execute_size\")\n",
    "  feature_names.remove(\"initial_iat_dll\")\n",
    "  feature_names.remove(\"initial_iat_func\")\n",
    "  feature_names.remove(\"initial_iat_malicious_func\")\n",
    "  feature_names.remove(\"number_add_exec_permission\")\n",
    "  feature_names.remove(\"number_add_write_permisison\")\n",
    "\n",
    "data = pd.read_csv(\"features/features_\" + name + \".csv\")\n",
    "labels = pd.read_csv(\"labels/labels_\" + name + \".csv\",header=None, names=['name', 'label'])\n",
    "data = data.merge(labels, on='name')\n",
    "\n",
    "names = data.loc[:,\"name\"]\n",
    "y = data.loc[:,\"label\"]\n",
    "X = data.drop([\"name\",\"label\",\"write_execute_size\",\"initial_iat_dll\",\"initial_iat_func\",\"initial_iat_malicious_func\",\"number_add_exec_permission\",\"number_add_write_permisison\"], axis = 1)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train1, y_test1 = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "packed = pd.read_csv(\"features/features_packed.csv\")\n",
    "notpacked = pd.read_csv(\"features/features_notpacked.csv\")\n",
    "packed1 = pd.read_csv(\"features/static_features_packed.csv\")\n",
    "notpacked1 = pd.read_csv(\"features/static_features_notpacked.csv\")\n",
    "packed = packed.merge(packed1[[\"name\"]], on='name')\n",
    "notpacked = notpacked.merge(notpacked1[[\"name\"]], on='name')\n",
    "X_clean = pd.concat([packed,notpacked], ignore_index = True)\n",
    "X_clean = X_clean.drop([\"name\",\"write_execute_size\",\"initial_iat_dll\",\"initial_iat_func\",\"initial_iat_malicious_func\",\"number_add_exec_permission\",\"number_add_write_permisison\"], axis = 1)\n",
    "y_clean = pd.DataFrame(np.append([True for i in range(len(packed))],[False for i in range(len(notpacked))])).iloc[:,0]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X_clean, y_clean):\n",
    "    X_train2, X_test2 = X_clean.iloc[train_index], X_clean.iloc[test_index]\n",
    "    y_train2, y_test2 = y_clean.iloc[train_index], y_clean.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train1,X_train2], ignore_index = True)\n",
    "y_train = pd.concat([y_train1,y_train2], ignore_index = True)\n",
    "X_test = pd.concat([X_test1,X_test2], ignore_index = True)\n",
    "y_test = pd.concat([y_test1,y_test2], ignore_index = True)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79517e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T15:22:10.345338Z",
     "iopub.status.busy": "2023-09-04T15:22:10.345101Z",
     "iopub.status.idle": "2023-09-04T15:24:07.359275Z",
     "shell.execute_reply": "2023-09-04T15:24:07.358086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 3} with a score of 0.90143\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=dt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_dynamic_DT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5ed477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T15:24:07.363482Z",
     "iopub.status.busy": "2023-09-04T15:24:07.363101Z",
     "iopub.status.idle": "2023-09-04T15:24:07.409744Z",
     "shell.execute_reply": "2023-09-04T15:24:07.408837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.96655\n",
      "The balance accuracy is 0.89661\n",
      "The precision is 0.97229\n",
      "The recall is 0.96088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.83      0.80       334\n",
      "        True       0.97      0.96      0.97      2045\n",
      "\n",
      "    accuracy                           0.94      2379\n",
      "   macro avg       0.87      0.90      0.89      2379\n",
      "weighted avg       0.94      0.94      0.94      2379\n",
      "\n",
      "The F1-score is 0.95916\n",
      "The balance accuracy is 0.88182\n",
      "The precision is 0.97039\n",
      "The recall is 0.94818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.82      0.76       233\n",
      "        True       0.97      0.95      0.96      1486\n",
      "\n",
      "    accuracy                           0.93      1719\n",
      "   macro avg       0.84      0.88      0.86      1719\n",
      "weighted avg       0.94      0.93      0.93      1719\n",
      "\n",
      "The F1-score is 0.98582\n",
      "The balance accuracy is 0.93296\n",
      "The precision is 0.97715\n",
      "The recall is 0.99463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.87      0.92       101\n",
      "        True       0.98      0.99      0.99       559\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.97      0.93      0.95       660\n",
      "weighted avg       0.98      0.98      0.98       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7836f94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T15:24:09.164078Z",
     "iopub.status.busy": "2023-09-04T15:24:09.163796Z",
     "iopub.status.idle": "2023-09-04T17:02:14.012020Z",
     "shell.execute_reply": "2023-09-04T17:02:14.011029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 20} with a score of 0.91087\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=rf, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_dynamic_RF.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1021c3ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:02:14.015862Z",
     "iopub.status.busy": "2023-09-04T17:02:14.015493Z",
     "iopub.status.idle": "2023-09-04T17:02:14.133846Z",
     "shell.execute_reply": "2023-09-04T17:02:14.133041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.97517\n",
      "The balance accuracy is 0.89991\n",
      "The precision is 0.97092\n",
      "The recall is 0.97946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.82      0.84       334\n",
      "        True       0.97      0.98      0.98      2045\n",
      "\n",
      "    accuracy                           0.96      2379\n",
      "   macro avg       0.92      0.90      0.91      2379\n",
      "weighted avg       0.96      0.96      0.96      2379\n",
      "\n",
      "The F1-score is 0.96815\n",
      "The balance accuracy is 0.87213\n",
      "The precision is 0.96460\n",
      "The recall is 0.97174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.77      0.79       233\n",
      "        True       0.96      0.97      0.97      1486\n",
      "\n",
      "    accuracy                           0.94      1719\n",
      "   macro avg       0.89      0.87      0.88      1719\n",
      "weighted avg       0.94      0.94      0.94      1719\n",
      "\n",
      "The F1-score is 0.99378\n",
      "The balance accuracy is 0.96535\n",
      "The precision is 0.98763\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.93      0.96       101\n",
      "        True       0.99      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.99       660\n",
      "   macro avg       0.99      0.97      0.98       660\n",
      "weighted avg       0.99      0.99      0.99       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de02d1a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:02:47.795642Z",
     "iopub.status.busy": "2023-09-04T17:02:47.795049Z",
     "iopub.status.idle": "2023-09-04T17:40:27.224103Z",
     "shell.execute_reply": "2023-09-04T17:40:27.220554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'max_depth': 12, 'min_samples_leaf': 10, 'n_estimators': 40} with a score of 0.90770\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [40]}\n",
    "gbdt = GradientBoostingClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=gbdt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_dynamic_GBDT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13418060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:40:27.228404Z",
     "iopub.status.busy": "2023-09-04T17:40:27.227704Z",
     "iopub.status.idle": "2023-09-04T17:40:27.281378Z",
     "shell.execute_reply": "2023-09-04T17:40:27.280164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.97785\n",
      "The balance accuracy is 0.90886\n",
      "The precision is 0.97335\n",
      "The recall is 0.98240\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.84      0.86       334\n",
      "        True       0.97      0.98      0.98      2045\n",
      "\n",
      "    accuracy                           0.96      2379\n",
      "   macro avg       0.93      0.91      0.92      2379\n",
      "weighted avg       0.96      0.96      0.96      2379\n",
      "\n",
      "The F1-score is 0.97283\n",
      "The balance accuracy is 0.89132\n",
      "The precision is 0.96990\n",
      "The recall is 0.97577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.81      0.82       233\n",
      "        True       0.97      0.98      0.97      1486\n",
      "\n",
      "    accuracy                           0.95      1719\n",
      "   macro avg       0.90      0.89      0.90      1719\n",
      "weighted avg       0.95      0.95      0.95      1719\n",
      "\n",
      "The F1-score is 0.99113\n",
      "The balance accuracy is 0.95050\n",
      "The precision is 0.98243\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.90      0.95       101\n",
      "        True       0.98      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.99      0.95      0.97       660\n",
      "weighted avg       0.99      0.98      0.98       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee98edc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:40:27.286085Z",
     "iopub.status.busy": "2023-09-04T17:40:27.285415Z",
     "iopub.status.idle": "2023-09-04T17:40:27.980612Z",
     "shell.execute_reply": "2023-09-04T17:40:27.979627Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"features/static_features_\" + name + \".csv\", \"r\") as f:\n",
    "  line = f.readline()\n",
    "  feature_names = line.split(\",\")\n",
    "  feature_names.pop(0)\n",
    "\n",
    "data = pd.read_csv(\"features/features_\" + name + \".csv\")\n",
    "labels = pd.read_csv(\"labels/labels_\" + name + \".csv\",header=None, names=['name', 'label'])\n",
    "data = data.merge(labels, on='name')\n",
    "data_static = pd.read_csv(\"features/static_features_\" + name + \".csv\")\n",
    "data_static = data_static.merge(data[[\"name\",\"label\"]], on='name')\n",
    "y = data_static.loc[:,\"label\"]\n",
    "X = data_static.drop([\"name\", \"label\"], axis = 1)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train1, y_test1 = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "packed1 = pd.read_csv(\"features/features_packed.csv\")\n",
    "notpacked1 = pd.read_csv(\"features/features_notpacked.csv\")\n",
    "packed = pd.read_csv(\"features/static_features_packed.csv\")\n",
    "notpacked = pd.read_csv(\"features/static_features_notpacked.csv\")\n",
    "packed = packed.merge(packed1[[\"name\"]], on='name')\n",
    "notpacked = notpacked.merge(notpacked1[[\"name\"]], on='name')\n",
    "X_clean = pd.concat([packed,notpacked], ignore_index = True)\n",
    "X_clean = X_clean.drop([\"name\"], axis = 1)\n",
    "y_clean = pd.DataFrame(np.append([True for i in range(len(packed))],[False for i in range(len(notpacked))])).iloc[:,0]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X_clean, y_clean):\n",
    "    X_train2, X_test2 = X_clean.iloc[train_index], X_clean.iloc[test_index]\n",
    "    y_train2, y_test2 = y_clean.iloc[train_index], y_clean.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train1,X_train2], ignore_index = True)\n",
    "y_train = pd.concat([y_train1,y_train2], ignore_index = True)\n",
    "X_test = pd.concat([X_test1,X_test2], ignore_index = True)\n",
    "y_test = pd.concat([y_test1,y_test2], ignore_index = True)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd83c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:40:28.024080Z",
     "iopub.status.busy": "2023-09-04T17:40:28.023316Z",
     "iopub.status.idle": "2023-09-04T17:42:02.508587Z",
     "shell.execute_reply": "2023-09-04T17:42:02.506567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 2} with a score of 0.86409\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=dt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_static_DT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc63c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:42:02.512242Z",
     "iopub.status.busy": "2023-09-04T17:42:02.511966Z",
     "iopub.status.idle": "2023-09-04T17:42:02.558180Z",
     "shell.execute_reply": "2023-09-04T17:42:02.557188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.95691\n",
      "The balance accuracy is 0.86578\n",
      "The precision is 0.96379\n",
      "The recall is 0.95012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.78      0.75       334\n",
      "        True       0.96      0.95      0.96      2045\n",
      "\n",
      "    accuracy                           0.93      2379\n",
      "   macro avg       0.84      0.87      0.85      2379\n",
      "weighted avg       0.93      0.93      0.93      2379\n",
      "\n",
      "The F1-score is 0.94568\n",
      "The balance accuracy is 0.84336\n",
      "The precision is 0.96044\n",
      "The recall is 0.93136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.76      0.69       233\n",
      "        True       0.96      0.93      0.95      1486\n",
      "\n",
      "    accuracy                           0.91      1719\n",
      "   macro avg       0.80      0.84      0.82      1719\n",
      "weighted avg       0.92      0.91      0.91      1719\n",
      "\n",
      "The F1-score is 0.98589\n",
      "The balance accuracy is 0.92079\n",
      "The precision is 0.97217\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.84      0.91       101\n",
      "        True       0.97      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.98       660\n",
      "   macro avg       0.99      0.92      0.95       660\n",
      "weighted avg       0.98      0.98      0.97       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdd7ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T17:42:04.363362Z",
     "iopub.status.busy": "2023-09-04T17:42:04.362636Z",
     "iopub.status.idle": "2023-09-04T19:00:52.401821Z",
     "shell.execute_reply": "2023-09-04T19:00:52.401050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 2, 'n_estimators': 39} with a score of 0.84392\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=rf, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_static_RF.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16913265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:00:52.406317Z",
     "iopub.status.busy": "2023-09-04T19:00:52.405736Z",
     "iopub.status.idle": "2023-09-04T19:00:52.477523Z",
     "shell.execute_reply": "2023-09-04T19:00:52.476923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.96863\n",
      "The balance accuracy is 0.85298\n",
      "The precision is 0.95617\n",
      "The recall is 0.98142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.72      0.79       334\n",
      "        True       0.96      0.98      0.97      2045\n",
      "\n",
      "    accuracy                           0.95      2379\n",
      "   macro avg       0.91      0.85      0.88      2379\n",
      "weighted avg       0.94      0.95      0.94      2379\n",
      "\n",
      "The F1-score is 0.96277\n",
      "The balance accuracy is 0.82842\n",
      "The precision is 0.95138\n",
      "The recall is 0.97443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.68      0.74       233\n",
      "        True       0.95      0.97      0.96      1486\n",
      "\n",
      "    accuracy                           0.93      1719\n",
      "   macro avg       0.88      0.83      0.85      1719\n",
      "weighted avg       0.93      0.93      0.93      1719\n",
      "\n",
      "The F1-score is 0.98415\n",
      "The balance accuracy is 0.91089\n",
      "The precision is 0.96880\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.82      0.90       101\n",
      "        True       0.97      1.00      0.98       559\n",
      "\n",
      "    accuracy                           0.97       660\n",
      "   macro avg       0.98      0.91      0.94       660\n",
      "weighted avg       0.97      0.97      0.97       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faccbe78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:01:23.910355Z",
     "iopub.status.busy": "2023-09-04T19:01:23.909945Z",
     "iopub.status.idle": "2023-09-04T19:32:07.822016Z",
     "shell.execute_reply": "2023-09-04T19:32:07.821173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'max_depth': 11, 'min_samples_leaf': 9, 'n_estimators': 40} with a score of 0.86813\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [40]}\n",
    "gbdt = GradientBoostingClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=gbdt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_static_GBDT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8503e9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:32:07.825803Z",
     "iopub.status.busy": "2023-09-04T19:32:07.825308Z",
     "iopub.status.idle": "2023-09-04T19:32:07.876785Z",
     "shell.execute_reply": "2023-09-04T19:32:07.876078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.96830\n",
      "The balance accuracy is 0.85900\n",
      "The precision is 0.95833\n",
      "The recall is 0.97848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.74      0.79       334\n",
      "        True       0.96      0.98      0.97      2045\n",
      "\n",
      "    accuracy                           0.94      2379\n",
      "   macro avg       0.90      0.86      0.88      2379\n",
      "weighted avg       0.94      0.94      0.94      2379\n",
      "\n",
      "The F1-score is 0.96197\n",
      "The balance accuracy is 0.83498\n",
      "The precision is 0.95370\n",
      "The recall is 0.97039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.70      0.74       233\n",
      "        True       0.95      0.97      0.96      1486\n",
      "\n",
      "    accuracy                           0.93      1719\n",
      "   macro avg       0.87      0.83      0.85      1719\n",
      "weighted avg       0.93      0.93      0.93      1719\n",
      "\n",
      "The F1-score is 0.98502\n",
      "The balance accuracy is 0.91584\n",
      "The precision is 0.97049\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.83      0.91       101\n",
      "        True       0.97      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.97       660\n",
      "   macro avg       0.99      0.92      0.95       660\n",
      "weighted avg       0.98      0.97      0.97       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce75708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:32:07.880031Z",
     "iopub.status.busy": "2023-09-04T19:32:07.879680Z",
     "iopub.status.idle": "2023-09-04T19:32:08.560370Z",
     "shell.execute_reply": "2023-09-04T19:32:08.559539Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"features/static_features_\" + name + \".csv\", \"r\") as f:\n",
    "  line = f.readline()\n",
    "  static_feature_names = line.split(\",\")\n",
    "  static_feature_names.pop(0)\n",
    "\n",
    "with open(\"features/features_\" + name + \".csv\", \"r\") as f:\n",
    "  line = f.readline()\n",
    "  feature_names = line.split(\",\")\n",
    "  feature_names.remove(\"name\")\n",
    "  feature_names.remove(\"write_execute_size\")\n",
    "  feature_names.remove(\"initial_iat_dll\")\n",
    "  feature_names.remove(\"initial_iat_func\")\n",
    "  feature_names.remove(\"initial_iat_malicious_func\")\n",
    "  feature_names.remove(\"number_add_exec_permission\")\n",
    "  feature_names.remove(\"number_add_write_permisison\")\n",
    "\n",
    "feature_names = np.concatenate((feature_names,static_feature_names),axis=None)\n",
    "\n",
    "data = pd.read_csv(\"features/features_\" + name + \".csv\")\n",
    "data_static = pd.read_csv(\"features/static_features_\" + name + \".csv\")\n",
    "data = data.merge(data_static, on='name')\n",
    "\n",
    "labels = pd.read_csv(\"labels/labels_\" + name + \".csv\",header=None, names=['name', 'label'])\n",
    "data = data.merge(labels, on='name')\n",
    "\n",
    "names = data.loc[:,\"name\"]\n",
    "y = data.loc[:,\"label\"]\n",
    "X = data.drop([\"name\",\"label\",\"write_execute_size\",\"initial_iat_dll\",\"initial_iat_func\",\"initial_iat_malicious_func\",\"number_add_exec_permission\",\"number_add_write_permisison\"], axis = 1)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train1, X_test1 = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train1, y_test1 = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "\n",
    "packed = pd.read_csv(\"features/features_packed.csv\")\n",
    "notpacked = pd.read_csv(\"features/features_notpacked.csv\")\n",
    "packed1 = pd.read_csv(\"features/static_features_packed.csv\")\n",
    "notpacked1 = pd.read_csv(\"features/static_features_notpacked.csv\")\n",
    "packed = packed.merge(packed1, on='name')\n",
    "notpacked = notpacked.merge(notpacked1, on='name')\n",
    "X_clean = pd.concat([packed,notpacked], ignore_index = True)\n",
    "X_clean = X_clean.drop([\"name\",\"write_execute_size\",\"initial_iat_dll\",\"initial_iat_func\",\"initial_iat_malicious_func\",\"number_add_exec_permission\",\"number_add_write_permisison\"], axis = 1)\n",
    "y_clean = pd.DataFrame(np.append([True for i in range(len(packed))],[False for i in range(len(notpacked))])).iloc[:,0]\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X_clean, y_clean):\n",
    "    X_train2, X_test2 = X_clean.iloc[train_index], X_clean.iloc[test_index]\n",
    "    y_train2, y_test2 = y_clean.iloc[train_index], y_clean.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train1,X_train2], ignore_index = True)\n",
    "y_train = pd.concat([y_train1,y_train2], ignore_index = True)\n",
    "X_test = pd.concat([X_test1,X_test2], ignore_index = True)\n",
    "y_test = pd.concat([y_test1,y_test2], ignore_index = True)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58280e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:32:08.603553Z",
     "iopub.status.busy": "2023-09-04T19:32:08.603175Z",
     "iopub.status.idle": "2023-09-04T19:35:45.224816Z",
     "shell.execute_reply": "2023-09-04T19:35:45.224022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 10} with a score of 0.92660\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=dt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_both_DT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fba791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:35:45.229663Z",
     "iopub.status.busy": "2023-09-04T19:35:45.229240Z",
     "iopub.status.idle": "2023-09-04T19:35:45.275638Z",
     "shell.execute_reply": "2023-09-04T19:35:45.274911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.96695\n",
      "The balance accuracy is 0.90586\n",
      "The precision is 0.97561\n",
      "The recall is 0.95844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.85      0.81       334\n",
      "        True       0.98      0.96      0.97      2045\n",
      "\n",
      "    accuracy                           0.94      2379\n",
      "   macro avg       0.87      0.91      0.89      2379\n",
      "weighted avg       0.95      0.94      0.94      2379\n",
      "\n",
      "The F1-score is 0.95664\n",
      "The balance accuracy is 0.88127\n",
      "The precision is 0.97089\n",
      "The recall is 0.94280\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.82      0.75       233\n",
      "        True       0.97      0.94      0.96      1486\n",
      "\n",
      "    accuracy                           0.93      1719\n",
      "   macro avg       0.83      0.88      0.85      1719\n",
      "weighted avg       0.93      0.93      0.93      1719\n",
      "\n",
      "The F1-score is 0.99378\n",
      "The balance accuracy is 0.96535\n",
      "The precision is 0.98763\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.93      0.96       101\n",
      "        True       0.99      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.99       660\n",
      "   macro avg       0.99      0.97      0.98       660\n",
      "weighted avg       0.99      0.99      0.99       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26675ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T19:35:46.236719Z",
     "iopub.status.busy": "2023-09-04T19:35:46.236322Z",
     "iopub.status.idle": "2023-09-04T21:06:13.254926Z",
     "shell.execute_reply": "2023-09-04T21:06:13.254087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 2, 'n_estimators': 28} with a score of 0.92429\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=rf, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_both_RF.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31aa25ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T21:06:13.260138Z",
     "iopub.status.busy": "2023-09-04T21:06:13.259786Z",
     "iopub.status.idle": "2023-09-04T21:06:13.319866Z",
     "shell.execute_reply": "2023-09-04T21:06:13.319013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.97923\n",
      "The balance accuracy is 0.92411\n",
      "The precision is 0.97852\n",
      "The recall is 0.97995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.87      0.87       334\n",
      "        True       0.98      0.98      0.98      2045\n",
      "\n",
      "    accuracy                           0.96      2379\n",
      "   macro avg       0.93      0.92      0.93      2379\n",
      "weighted avg       0.96      0.96      0.96      2379\n",
      "\n",
      "The F1-score is 0.97306\n",
      "The balance accuracy is 0.90251\n",
      "The precision is 0.97372\n",
      "The recall is 0.97241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.83      0.83       233\n",
      "        True       0.97      0.97      0.97      1486\n",
      "\n",
      "    accuracy                           0.95      1719\n",
      "   macro avg       0.90      0.90      0.90      1719\n",
      "weighted avg       0.95      0.95      0.95      1719\n",
      "\n",
      "The F1-score is 0.99555\n",
      "The balance accuracy is 0.97525\n",
      "The precision is 0.99113\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.95      0.97       101\n",
      "        True       0.99      1.00      1.00       559\n",
      "\n",
      "    accuracy                           0.99       660\n",
      "   macro avg       1.00      0.98      0.99       660\n",
      "weighted avg       0.99      0.99      0.99       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a3a8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T21:06:37.554842Z",
     "iopub.status.busy": "2023-09-04T21:06:37.554308Z",
     "iopub.status.idle": "2023-09-04T21:40:57.163502Z",
     "shell.execute_reply": "2023-09-04T21:40:57.162623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'max_depth': 9, 'min_samples_leaf': 9, 'n_estimators': 40} with a score of 0.93351\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [40]}\n",
    "gbdt = GradientBoostingClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=gbdt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.5f\"% (search.best_params_, search.best_score_))\n",
    "model = search.best_estimator_\n",
    "pickle.dump(model, open(\"models/mix_both_GBDT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af7931e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T21:40:57.235289Z",
     "iopub.status.busy": "2023-09-04T21:40:57.235009Z",
     "iopub.status.idle": "2023-09-04T21:40:57.286840Z",
     "shell.execute_reply": "2023-09-04T21:40:57.286020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score is 0.98143\n",
      "The balance accuracy is 0.93257\n",
      "The precision is 0.98095\n",
      "The recall is 0.98191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.88      0.89       334\n",
      "        True       0.98      0.98      0.98      2045\n",
      "\n",
      "    accuracy                           0.97      2379\n",
      "   macro avg       0.93      0.93      0.93      2379\n",
      "weighted avg       0.97      0.97      0.97      2379\n",
      "\n",
      "The F1-score is 0.97642\n",
      "The balance accuracy is 0.91674\n",
      "The precision is 0.97773\n",
      "The recall is 0.97510\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       233\n",
      "        True       0.98      0.98      0.98      1486\n",
      "\n",
      "    accuracy                           0.96      1719\n",
      "   macro avg       0.91      0.92      0.91      1719\n",
      "weighted avg       0.96      0.96      0.96      1719\n",
      "\n",
      "The F1-score is 0.99466\n",
      "The balance accuracy is 0.97030\n",
      "The precision is 0.98938\n",
      "The recall is 1.00000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.94      0.97       101\n",
      "        True       0.99      1.00      0.99       559\n",
      "\n",
      "    accuracy                           0.99       660\n",
      "   macro avg       0.99      0.97      0.98       660\n",
      "weighted avg       0.99      0.99      0.99       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test,y_pred))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test,y_pred))\n",
    ")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test1,y_pred1))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test1,y_pred1))\n",
    ")\n",
    "print(classification_report(y_test1,y_pred1))\n",
    "\n",
    "y_pred2 = model.predict(X_test2)\n",
    "print(\n",
    "    \"The F1-score is %0.5f\"\n",
    "    % (f1_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The balance accuracy is %0.5f\"\n",
    "    % (balanced_accuracy_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The precision is %0.5f\"\n",
    "    % (precision_score(y_test2,y_pred2))\n",
    ")\n",
    "print(\n",
    "    \"The recall is %0.5f\"\n",
    "    % (recall_score(y_test2,y_pred2))\n",
    ")\n",
    "print(classification_report(y_test2,y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
