{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa2a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "import sys\n",
    "    \n",
    "packed = np.genfromtxt('features/features_packed.csv', delimiter=',')\n",
    "packed = np.delete(packed,0,0)\n",
    "packed = np.delete(packed,0,1)\n",
    "y1 = np.ones(len(packed))\n",
    "\n",
    "packed_train,packed_test = np.split(packed,[int(0.7 * len(packed))])\n",
    "y1_train,y1_test = np.split(y1,[int(0.7 * len(y1))])\n",
    "\n",
    "notpacked = np.genfromtxt('features/features_notpacked.csv', delimiter=',')\n",
    "notpacked = np.delete(notpacked,0,0)\n",
    "notpacked = np.delete(notpacked,0,1)\n",
    "y0 = np.zeros(len(notpacked))\n",
    "\n",
    "notpacked_train,notpacked_test = np.split(notpacked,[int(0.7 * len(notpacked))])\n",
    "y0_train,y0_test = np.split(y0,[int(0.7 * len(y0))])\n",
    "\n",
    "X = np.append(packed_train,notpacked_train, axis = 0)\n",
    "y = np.append(y1_train,y0_train, axis = 0)\n",
    "\n",
    "X1 = np.append(packed_test,notpacked_test, axis = 0)\n",
    "y1 = np.append(y1_test,y0_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9042f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 2} with a score of 0.99065 in training and a score of 0.99563 in testing\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=dt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7f4000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 2, 'n_estimators': 15} with a score of 1.00000 in training and a score of 1.00000 in testing\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=rf, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a329ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'friedman_mse', 'loss': 'exponential', 'max_depth': 2, 'min_samples_leaf': 2, 'n_estimators': 36} with a score of 0.99583 in training and a score of 1.00000 in testing\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"criterion\":[\"friedman_mse\",\"squared_error\"],\"loss\": [\"log_loss\",\"exponential\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "gbdt = GradientBoostingClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=gbdt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa5114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = np.genfromtxt('features/static_features_packed.csv', delimiter=',')\n",
    "packed = np.delete(packed,0,1)\n",
    "y1 = np.ones(len(packed))\n",
    "\n",
    "packed_train,packed_test = np.split(packed,[int(0.7 * len(packed))])\n",
    "y1_train,y1_test = np.split(y1,[int(0.7 * len(y1))])\n",
    "\n",
    "notpacked = np.genfromtxt('features/static_features_notpacked.csv', delimiter=',')\n",
    "notpacked = np.delete(notpacked,0,1)\n",
    "y0 = np.zeros(len(notpacked))\n",
    "\n",
    "notpacked_train,notpacked_test = np.split(notpacked,[int(0.7 * len(notpacked))])\n",
    "y0_train,y0_test = np.split(y0,[int(0.7 * len(y0))])\n",
    "\n",
    "X = np.append(packed_train,notpacked_train, axis = 0)\n",
    "y = np.append(y1_train,y0_train, axis = 0)\n",
    "\n",
    "X1 = np.append(packed_test,notpacked_test, axis = 0)\n",
    "y1 = np.append(y1_test,y0_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a90afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 4} with a score of 0.95605 in training and a score of 0.92959 in testing\n"
     ]
    }
   ],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=dt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0768dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  {\"criterion\": [\"gini\",\"entropy\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "rf = RandomForestClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=rf, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\":[\"friedman_mse\",\"squared_error\"],\"loss\": [\"log_loss\",\"exponential\"],\"min_samples_leaf\":[2,3,4,5,6,7,8,9,10,11,12],\"max_depth\":[1,2,3,4,5,6,7,8,9,10,11,12],\"n_estimators\" : [i for i in range(10,40)]}\n",
    "gbdt = GradientBoostingClassifier(random_state = 0)\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "search = GridSearchCV(estimator=gbdt, param_grid=param_grid, cv = cv, scoring = \"balanced_accuracy\", n_jobs = -1)\n",
    "search.fit(X, y)\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.5f in training and a score of %0.5f in testing\"\n",
    "    % (search.best_params_, search.best_score_,search.best_estimator_.score(X1,y1))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
